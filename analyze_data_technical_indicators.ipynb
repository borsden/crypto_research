{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-12T07:55:55.382729Z",
     "start_time": "2023-12-12T07:55:55.340953Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "\n",
    "import pathlib\n",
    "import itertools\n",
    "import warnings\n",
    "import collections\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T07:55:56.245938Z",
     "start_time": "2023-12-12T07:55:55.375637Z"
    }
   },
   "id": "6624fa5ea7c92e94"
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:13,  3.68it/s]\n",
      "50it [00:00, 106.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from binance.enums import KLINE_INTERVAL_1HOUR, KLINE_INTERVAL_1DAY\n",
    "from crypto_research.analysis.signals.technical import SIGNALS_1H, SIGNALS_1D\n",
    "\n",
    "DATA_PATH = pathlib.Path(\"/Users/borsden/Projects/crypto_research/data\")\n",
    "def get_data(interval: int):\n",
    "    \"\"\"Use cached version of data instead of influxdb\"\"\"\n",
    "    data_path = DATA_PATH / interval\n",
    "    pairs_paths = data_path.glob(\"*.csv\")\n",
    "    for pair_path in tqdm.tqdm(pairs_paths):\n",
    "        data = pd.read_csv(pair_path, index_col=['time'], parse_dates=['time'])\n",
    "        # Todo: OHLC is for x:59:59 ...  - That is OK for testing purposes to round it to next time instead.\n",
    "        data.index = data.index.round('H')\n",
    "        yield pair_path.stem, data\n",
    "\n",
    "        \n",
    "INTERVALS = {\n",
    "    KLINE_INTERVAL_1HOUR,\n",
    "    KLINE_INTERVAL_1DAY\n",
    "}\n",
    "\n",
    "SIGNALS_DICT = {KLINE_INTERVAL_1HOUR: SIGNALS_1H, KLINE_INTERVAL_1DAY: SIGNALS_1D}\n",
    "\n",
    "DATA = {}\n",
    "for interval in INTERVALS:\n",
    "    DATA[interval] = dict(get_data(interval))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T12:51:53.799910Z",
     "start_time": "2023-12-12T12:51:39.696215Z"
    }
   },
   "id": "9c37f3eade2e091"
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:00<00:00,  1.20s/it]\n"
     ]
    }
   ],
   "source": [
    "from crypto_research.analysis.signals import combine_signals\n",
    "\n",
    "\n",
    "def _iterator(data):\n",
    "    for interval, interval_data in data.items():\n",
    "        for pair, pair_data in interval_data.items():\n",
    "            yield pair, pair_data, interval\n",
    "\n",
    "iterator = list(_iterator(DATA))\n",
    "\n",
    "PAIRS_FEATURES = collections.defaultdict(dict)\n",
    "for pair, pair_data, interval in tqdm.tqdm(iterator):\n",
    "    signal_dict = SIGNALS_DICT[interval]\n",
    "    indicators, signals = combine_signals(pair_data, signal_dict)\n",
    "    \n",
    "    # # We shift to 1 because they used to be predictive signals.\n",
    "    # indicators = indicators\n",
    "    # signals = signals\n",
    "    \n",
    "    PAIRS_FEATURES[pair][interval] = signals\n",
    "    \n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:09:46.434083Z",
     "start_time": "2023-12-12T13:07:44.398977Z"
    }
   },
   "id": "7d85f5f4eca060b9"
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "HORIZONS = [1, 2, 3, 5, 8, 13, 21]\n",
    "\n",
    "def get_returns_diff(close: pd.Series, horizons=HORIZONS):\n",
    "    \"\"\"Calculate diff returns for \"\"\"\n",
    "    returns_diff = []\n",
    "    \n",
    "    returns_diff_1 = close.pct_change()\n",
    "    for horizon in horizons:\n",
    "        returns_diff_horizon = (1 + returns_diff_1).rolling(window=horizon).apply(np.prod, raw=True) - 1\n",
    "        # Shift it because they expect to be predictive variables.\n",
    "        returns_diff_horizon = returns_diff_horizon.shift(-horizon)\n",
    "        returns_diff_horizon.name = horizon\n",
    "        returns_diff.append(returns_diff_horizon)\n",
    "    returns_diff = pd.concat(returns_diff, axis=1)\n",
    "    return returns_diff\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:10:58.664435Z",
     "start_time": "2023-12-12T13:10:58.601474Z"
    }
   },
   "id": "e1201262abf1f937"
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.00it/s]\n"
     ]
    }
   ],
   "source": [
    "PAIR_RETURNS = collections.defaultdict(dict)\n",
    "for pair, pair_data, interval in tqdm.tqdm(iterator):\n",
    "    PAIR_RETURNS[pair][interval] = get_returns_diff(pair_data.close)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:11:20.928056Z",
     "start_time": "2023-12-12T13:11:00.905284Z"
    }
   },
   "id": "84b89fa384dd99b2"
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 1         2         3         5         8   \\\ntime                                                                          \n2020-12-13 00:00:00+00:00  0.019951  0.025037  0.033240  0.213670  0.248562   \n2020-12-14 00:00:00+00:00  0.004987  0.013029  0.113258  0.205959  0.185399   \n2020-12-15 00:00:00+00:00  0.008002  0.107734  0.184025  0.237489  0.236436   \n2020-12-16 00:00:00+00:00  0.098939  0.174625  0.190448  0.208395  0.196313   \n2020-12-17 00:00:00+00:00  0.068872  0.083270  0.117136  0.064801  0.111991   \n...                             ...       ...       ...       ...       ...   \n2023-12-08 00:00:00+00:00  0.021099  0.010123  0.011872       NaN       NaN   \n2023-12-09 00:00:00+00:00 -0.010749 -0.009037 -0.042222       NaN       NaN   \n2023-12-10 00:00:00+00:00  0.001731 -0.031815       NaN       NaN       NaN   \n2023-12-11 00:00:00+00:00 -0.033488       NaN       NaN       NaN       NaN   \n2023-12-12 00:00:00+00:00       NaN       NaN       NaN       NaN       NaN   \n\n                                 13        21  \ntime                                           \n2020-12-13 00:00:00+00:00  0.315426  0.712761  \n2020-12-14 00:00:00+00:00  0.382463  0.723828  \n2020-12-15 00:00:00+00:00  0.365059  0.662164  \n2020-12-16 00:00:00+00:00  0.395253  0.750305  \n2020-12-17 00:00:00+00:00  0.283697  0.725021  \n...                             ...       ...  \n2023-12-08 00:00:00+00:00       NaN       NaN  \n2023-12-09 00:00:00+00:00       NaN       NaN  \n2023-12-10 00:00:00+00:00       NaN       NaN  \n2023-12-11 00:00:00+00:00       NaN       NaN  \n2023-12-12 00:00:00+00:00       NaN       NaN  \n\n[1095 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>5</th>\n      <th>8</th>\n      <th>13</th>\n      <th>21</th>\n    </tr>\n    <tr>\n      <th>time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-12-13 00:00:00+00:00</th>\n      <td>0.019951</td>\n      <td>0.025037</td>\n      <td>0.033240</td>\n      <td>0.213670</td>\n      <td>0.248562</td>\n      <td>0.315426</td>\n      <td>0.712761</td>\n    </tr>\n    <tr>\n      <th>2020-12-14 00:00:00+00:00</th>\n      <td>0.004987</td>\n      <td>0.013029</td>\n      <td>0.113258</td>\n      <td>0.205959</td>\n      <td>0.185399</td>\n      <td>0.382463</td>\n      <td>0.723828</td>\n    </tr>\n    <tr>\n      <th>2020-12-15 00:00:00+00:00</th>\n      <td>0.008002</td>\n      <td>0.107734</td>\n      <td>0.184025</td>\n      <td>0.237489</td>\n      <td>0.236436</td>\n      <td>0.365059</td>\n      <td>0.662164</td>\n    </tr>\n    <tr>\n      <th>2020-12-16 00:00:00+00:00</th>\n      <td>0.098939</td>\n      <td>0.174625</td>\n      <td>0.190448</td>\n      <td>0.208395</td>\n      <td>0.196313</td>\n      <td>0.395253</td>\n      <td>0.750305</td>\n    </tr>\n    <tr>\n      <th>2020-12-17 00:00:00+00:00</th>\n      <td>0.068872</td>\n      <td>0.083270</td>\n      <td>0.117136</td>\n      <td>0.064801</td>\n      <td>0.111991</td>\n      <td>0.283697</td>\n      <td>0.725021</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2023-12-08 00:00:00+00:00</th>\n      <td>0.021099</td>\n      <td>0.010123</td>\n      <td>0.011872</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2023-12-09 00:00:00+00:00</th>\n      <td>-0.010749</td>\n      <td>-0.009037</td>\n      <td>-0.042222</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2023-12-10 00:00:00+00:00</th>\n      <td>0.001731</td>\n      <td>-0.031815</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2023-12-11 00:00:00+00:00</th>\n      <td>-0.033488</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2023-12-12 00:00:00+00:00</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1095 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAIR_RETURNS['btcusdt']['1d']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:11:23.453338Z",
     "start_time": "2023-12-12T13:11:23.414274Z"
    }
   },
   "id": "190c0061815b8cb"
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 11.36it/s]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "def add_prefix_to_columns(df, prefix):\n",
    "    \"\"\"\n",
    "    Add a prefix to each column name in a dataframe.\n",
    "    \"\"\"\n",
    "    return df.add_prefix(prefix)\n",
    "\n",
    "def resample_daily_data_to_hourly(df):\n",
    "    \"\"\"\n",
    "    Resample daily dataframe to hourly frequency by forward-filling.\n",
    "    \"\"\"\n",
    "    return df.resample('H').ffill()\n",
    "\n",
    "def merge_hourly_and_daily_data(hourly_df, daily_df):\n",
    "    \"\"\"\n",
    "    Merge hourly and daily dataframes on the hourly timestamps.\n",
    "    \"\"\"\n",
    "    hourly_df = add_prefix_to_columns(hourly_df, '1h_')\n",
    "    daily_df = add_prefix_to_columns(daily_df, '1d_')\n",
    "    daily_df_resampled = resample_daily_data_to_hourly(daily_df)\n",
    "    \n",
    "    return hourly_df.merge(daily_df_resampled, left_index=True, right_index=True, how='left')\n",
    "        \n",
    "for pair, features in tqdm.tqdm(PAIRS_FEATURES.items()):\n",
    "    features['merged'] = merge_hourly_and_daily_data(\n",
    "        features[KLINE_INTERVAL_1HOUR], features[KLINE_INTERVAL_1DAY]\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:11:37.499927Z",
     "start_time": "2023-12-12T13:11:33.043952Z"
    }
   },
   "id": "b2f8fd1b4bf937f5"
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "# RESULTS = collections.defaultdict(dict)\n",
    "# for pair, interval, features, ret, returns in tqdm.tqdm(_iterator()):\n",
    "#     result = run_models(features, returns, models)\n",
    "#     RESULTS[pair][(interval, ret)] = dict(result)\n",
    "#     break\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T13:11:44.690693Z",
     "start_time": "2023-12-12T13:11:44.638044Z"
    }
   },
   "id": "8358405e8233aed1"
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [],
   "source": [
    "\n",
    "# def iterator_for_models():\n",
    "#     for pair, _, interval in iterator:\n",
    "#         returns_all = PAIR_RETURNS[pair][interval].fillna(0)\n",
    "#         features = PAIRS_FEATURES[pair][interval]\n",
    "#         for ret in returns_all.columns:\n",
    "#             returns = returns_all[ret]\n",
    "#             yield pair, interval, features, ret, returns\n",
    "\n",
    "def categorize_by_percentile(data, lower_percentile, upper_percentile):\n",
    "    \"\"\"\n",
    "    Categorize data based on percentile thresholds.\n",
    "    \"\"\"\n",
    "    \n",
    "    categorized_data = pd.Series(index=data.index)\n",
    "\n",
    "    categorized_data[data < lower_percentile] = -1  # Below 25th percentile\n",
    "    categorized_data[data > upper_percentile] = 1   # Above 75th percentile\n",
    "    categorized_data[(data >= lower_percentile) & (data <= upper_percentile)] = 0  # Between 25th and 75th percentile\n",
    "\n",
    "    return categorized_data\n",
    "\n",
    "def backtest_strategy(buy_sell, actual_returns):\n",
    "    \"\"\"\n",
    "    Backtest the trading strategy.\n",
    "\n",
    "    \"\"\"\n",
    "    strategy_returns = buy_sell * actual_returns\n",
    "    \n",
    "    cumulative_returns = (1 + strategy_returns).cumprod()\n",
    "\n",
    "    sharpe_ratio = np.mean(strategy_returns) / np.std(strategy_returns)\n",
    "    print(sharpe_ratio)\n",
    "    max_drawdown = np.min(cumulative_returns) / np.max(cumulative_returns) - 1\n",
    "    results = {\n",
    "        'Cumulative Returns': cumulative_returns.iloc[-1],\n",
    "        'Sharpe Ratio': sharpe_ratio,\n",
    "        'Max Drawdown': max_drawdown\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "from crypto_research.analysis.models import CatBoostRegressor, LassoRegressor, RandomForestRegressor\n",
    "from crypto_research.analysis.models.utils import get_IS_OS\n",
    "from sklearn.metrics import mean_squared_error\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T14:05:41.220498Z",
     "start_time": "2023-12-12T14:05:41.166109Z"
    }
   },
   "id": "61bd2e13c385680b"
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|█████     | 1/2 [00:26<00:26, 26.79s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43526106696356176\n",
      "0.0067020864632584545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vz/bdwl1bzx5q75c06lpdm0dhzc0000gn/T/ipykernel_63212/3060188461.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  sharpe_ratio = np.mean(strategy_returns) / np.std(strategy_returns)\n",
      "\n",
      "100%|██████████| 2/2 [00:27<00:00, 13.61s/it]\u001B[A\n",
      "  0%|          | 0/7 [00:27<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "RATIO = 0.8\n",
    "\n",
    "pair = 'btcusdt'\n",
    "interval = '1h'\n",
    "features = PAIRS_FEATURES[pair][interval]\n",
    "returns = PAIR_RETURNS[pair][interval]\n",
    "\n",
    "LOWER, UPPER = 0.2, 0.8\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "RESULTS = collections.defaultdict(dict)\n",
    "train_X, test_X = get_IS_OS(features, RATIO)\n",
    "\n",
    "for ret_pred_distance in tqdm.tqdm(returns.columns):\n",
    "    ret_X = returns[ret_pred_distance]\n",
    "    # Todo: add some metrics to evaluate quality of models.\n",
    "    train_y, test_y = get_IS_OS(ret_X.fillna(0), RATIO)\n",
    "    models = [CatBoostRegressor(verbose=False), LassoRegressor()]\n",
    "    for model in tqdm.tqdm(models):\n",
    "        # model.fit(train_X, train_y, eval_set=(test_X, test_y))\n",
    "        model.fit(train_X, train_y)\n",
    "        \n",
    "        train_predict = model.predict(train_X)\n",
    "        test_predict = model.predict(test_X)\n",
    "        \n",
    "        lower_percentile = train_predict.quantile(LOWER)\n",
    "        upper_percentile = train_predict.quantile(UPPER)\n",
    "        \n",
    "        categorized_train_predict = categorize_by_percentile(train_predict, lower_percentile, upper_percentile)\n",
    "        categorized_test_predict = categorize_by_percentile(test_predict, lower_percentile, upper_percentile)\n",
    "        \n",
    "        train_metrics = backtest_strategy(categorized_train_predict, train_y)\n",
    "        test_metrics = backtest_strategy(categorized_test_predict, test_y)\n",
    "        RESULTS[ret_pred_distance][model.__class__.__name__] = [train_metrics, test_metrics]\n",
    "    break\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T14:06:11.457457Z",
     "start_time": "2023-12-12T14:05:44.164098Z"
    }
   },
   "id": "dad0ba3c39487e0c"
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "outputs": [
    {
     "data": {
      "text/plain": "   return              model  TRAIN_Cumulative Returns  TRAIN_Sharpe Ratio  \\\n0       1  CatBoostRegressor                  1.641723            0.435261   \n1       1     LassoRegressor                  1.641723                 NaN   \n\n   TRAIN_Max Drawdown  TEST_Cumulative Returns  TEST_Sharpe Ratio  \\\n0           -0.772423                 1.434186           0.006702   \n1           -0.772423                 1.434186                NaN   \n\n   TEST_Max Drawdown  \n0          -0.441095  \n1          -0.441095  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>return</th>\n      <th>model</th>\n      <th>TRAIN_Cumulative Returns</th>\n      <th>TRAIN_Sharpe Ratio</th>\n      <th>TRAIN_Max Drawdown</th>\n      <th>TEST_Cumulative Returns</th>\n      <th>TEST_Sharpe Ratio</th>\n      <th>TEST_Max Drawdown</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>CatBoostRegressor</td>\n      <td>1.641723</td>\n      <td>0.435261</td>\n      <td>-0.772423</td>\n      <td>1.434186</td>\n      <td>0.006702</td>\n      <td>-0.441095</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>LassoRegressor</td>\n      <td>1.641723</td>\n      <td>NaN</td>\n      <td>-0.772423</td>\n      <td>1.434186</td>\n      <td>NaN</td>\n      <td>-0.441095</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def result_iterator(result):\n",
    "    for ret, vals in result.items():\n",
    "        for model, (train, test) in vals.items():\n",
    "            train = {f\"TRAIN_{k}\": v for k, v in train.items()}\n",
    "            test = {f\"TEST_{k}\": v for k, v in test.items()}\n",
    "            yield {\n",
    "                'return': ret, 'model': model, **train, **test\n",
    "            }\n",
    "pd.DataFrame(list(result_iterator(result)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T14:03:00.252177Z",
     "start_time": "2023-12-12T14:03:00.187566Z"
    }
   },
   "id": "f3bcd66ff9c19869"
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [
    {
     "data": {
      "text/plain": "defaultdict(dict,\n            {1: {'CatBoostRegressor': [{'Cumulative Returns': 1.641722729980654,\n                'Sharpe Ratio': 0.43526106696356176,\n                'Max Drawdown': -0.7724232825946666},\n               {'Cumulative Returns': 1.4341862943004715,\n                'Sharpe Ratio': 0.0067020864632584545,\n                'Max Drawdown': -0.4410953064704307}],\n              'LassoRegressor': [{'Cumulative Returns': 1.641722729980654,\n                'Sharpe Ratio': nan,\n                'Max Drawdown': -0.7724232825946666},\n               {'Cumulative Returns': 1.4341862943004715,\n                'Sharpe Ratio': nan,\n                'Max Drawdown': -0.4410953064704307}]}})"
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T14:01:45.745101Z",
     "start_time": "2023-12-12T14:01:45.655337Z"
    }
   },
   "id": "99d42a2a7997ed0f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c3e8fa53704cbdff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
